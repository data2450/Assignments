# -*- coding: utf-8 -*-
"""embed-store.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eZA9VFJMv9YHF6Pc8iuzsP08Fa9ArS4r
"""

import nltk
nltk.download('punkt_tab')
import re
from nltk.tokenize import sent_tokenize
nltk.download("punkt")

import re
from nltk.tokenize import sent_tokenize
from sentence_transformers import SentenceTransformer
import faiss  # Or Chroma, Milvus - choose one

#give ure paragraph
paragraphs = [
    "Artificial intelligence (AI) is rapidly transforming the healthcare landscape. From diagnosing diseases with greater accuracy to personalizing treatment plans, AI offers the potential to revolutionize patient care. Machine learning algorithms can analyze vast amounts of medical data, including patient records, medical images, and genetic information, to identify patterns and insights that would be impossible for humans to detect. This can lead to earlier and more accurate diagnoses, as well as the development of targeted therapies tailored to individual patients.",
    "One promising application of AI in healthcare is in the field of medical imaging. AI-powered systems can analyze X-rays, CT scans, and MRIs to detect abnormalities and assist radiologists in making diagnoses. For example, AI algorithms have shown great promise in detecting early signs of cancer, often outperforming human experts in certain tasks. This can lead to earlier treatment and improved outcomes for patients. Furthermore, AI can help reduce the workload on radiologists, allowing them to focus on more complex cases.",
    "Another area where AI is making significant strides in healthcare is in drug discovery and development. Developing new drugs is a time-consuming and expensive process, but AI can accelerate this process by analyzing vast datasets of molecular information to identify potential drug candidates. AI can also be used to predict the efficacy and safety of drugs, reducing the number of failed clinical trials. This can lead to the development of new treatments for a wide range of diseases, including cancer, Alzheimer's disease, and infectious diseases.",
    "Despite the potential benefits, there are also challenges associated with the use of AI in healthcare. One concern is the need for large amounts of high-quality data to train AI algorithms. Another challenge is ensuring the privacy and security of patient data. Furthermore, it is important to address ethical considerations related to the use of AI in healthcare, such as bias in algorithms and the potential impact on the doctor-patient relationship. Overcoming these challenges will be crucial for realizing the full potential of AI in healthcare.",
    "The future of AI in healthcare is bright. As AI technology continues to advance, we can expect to see even more innovative applications emerge. From AI-powered virtual assistants that can provide personalized health advice to robotic surgery systems that can perform complex procedures with greater precision, AI has the potential to transform every aspect of healthcare. While challenges remain, the potential benefits of AI in healthcare are immense, and its continued development promises to improve the lives of millions of people around the world."
]

import re
import nltk
from nltk.tokenize import sent_tokenize

nltk.download("punkt", quiet=True) # Download punkt only if not already downloaded

def preprocess_text(text):
    """Remove extra whitespaces and normalize text."""
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def chunk_text(text, chunk_size=200):
    """Split text into chunks of ~200 words while preserving sentence boundaries."""
    sentences = sent_tokenize(text)  # Split text into sentences
    chunks = []
    current_chunk = []
    current_length = 0

    for sentence in sentences:
        sentence_length = len(sentence.split())
        if current_length + sentence_length > chunk_size:
            chunks.append(" ".join(current_chunk))
            current_chunk = []
            current_length = 0

        current_chunk.append(sentence)
        current_length += sentence_length

    if current_chunk:
        chunks.append(" ".join(current_chunk))  # Append last chunk

    return chunks

# Process each paragraph
processed_chunks = []
for paragraph in paragraphs:
    preprocessed_paragraph = preprocess_text(paragraph)
    chunks = chunk_text(preprocessed_paragraph)
    processed_chunks.extend(chunks) # Add the chunks to the list

# ... (preprocess_text and chunk_text functions from previous response) ...

# Initialize Sentence Transformer model
model = SentenceTransformer('all-mpnet-base-v2') # Or any other sentence-transformer model

# Initialize FAISS index (example - adapt for Chroma/Milvus)
d = model.get_sentence_embedding_dimension()  # Embedding dimension
index = faiss.IndexFlatL2(d)  # L2 distance for similarity search

# Your list of paragraphs (replace with your actual paragraphs)


# Embed and add to vector store
embeddings = []
for i, chunk in enumerate(processed_chunks):
    embedding = model.encode(chunk)
    embeddings.append(embedding)
    index.add(embedding.reshape(1, d)) # FAISS needs a 2D array (even for one vector)


def retrieve_chunks(query, top_k=3):
    query_embedding = model.encode(query)
    D, I = index.search(query_embedding.reshape(1, d), top_k)  # Search top_k nearest neighbors
    retrieved_chunks = [processed_chunks[i] for i in I[0]] # Get the chunks based on indices
    return retrieved_chunks, D[0] # Return chunks and distances


# Example usage:
query = "What are the challenges of using AI in healthcare?"
retrieved_chunks, distances = retrieve_chunks(query)

print(f"Query: {query}\n")
for i, chunk in enumerate(retrieved_chunks):
    print(f"Retrieved Chunk {i+1} (Distance: {distances[i]}):\n{chunk}\n")
    print("-" * 20)

